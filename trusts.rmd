---
bibliography: trusts/bibliography.bib
fontsize: 10pt
urlcolor: olive
documentclass:
    - article
classoption:
    - twocolumn
geometry:
    - letterpaper
    - columnsep = 0.5in
    - hmargin = 0.65in
    - vmargin = 1.0in
output:
    rmarkdown::pdf_document:
    keep_tex: FALSE
    citation_package: "default"
    number_sections: FALSE
    extra_dependencies:
        - booktabs
header-includes:
    - \usepackage{color}
    - \usepackage{caption}
    - \usepackage{booktabs}
    - \captionsetup[figure]{font={footnotesize, color=gray}, width=.8\linewidth}
    - \captionsetup[table]{font={footnotesize, color=gray}, width=.8\linewidth}
    - \usepackage{xcolor}
    - \usepackage{titlesec}
    - \usepackage{tikz}
    - \usetikzlibrary{shapes.geometric, arrows.meta, matrix, arrows, automata, positioning, shadows, trees}
    - \definecolor{darkgrey}{rgb}{.45,.45,.45}
    - \titleformat*{\subsection}{\bfseries\large\color{darkgrey}}
---

<!--- Global Settings --->
```{r include = FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


<!--- Libraries --->
```{r include = FALSE}
library(ggplot2)
library(dplyr)
library(tidyr)
library(stringr)
library(magrittr)
library(latex2exp)
```


```{r}
sys.source(file = 'R/EvaluationHistoriesData.R', envir = knitr::knit_global())
sys.source(file = 'R/EvaluationHistories.R', envir = knitr::knit_global())
sys.source(file = 'R/EvaluationEndpointsData.R', envir = knitr::knit_global())
sys.source(file = 'R/EvaluationEndpoints.R', envir = knitr::knit_global())
```

# INTRODUCTION

Since late January 2020, there have been over 17,515,199 cases of SARS-CoV-2 infections in the United Kingdom (UK) [@Flynn2020]. This virus can cause high fever, coughing, shortness of breath, pneumonia, as well as serious respiratory infections \textcolor{blue}{MISSING REF: Original reference required}. The growing number of daily infections and hospitalisations in the UK constitute a serious threat to an already overburdened healthcare system . Indeed, the National Health Service (NHS) cannot meet the needs of many patients with urgent medical conditions due to overcrowded hospitals \textcolor{blue}{MISSING REF: Original reference required}.

It is essential to monitor and forecast new inpatient admissions \textcolor{blue}{in order to} manage hospital resources efficiently, reduce overcrowding, and improve the quality of care received \textcolor{blue}{MISSING REF ...}. Therefore, this study focuses on the development of a coronavirus 19 disease new inpatients' prediction model.  Addressing this research question may help improve NHS performance and patient outcomes by providing more efficient and higher-quality patient care and optimising the allocation of limited resources to meet the growing demand for hospital places \textcolor{blue}{MISSING REF: Huang2019}.

The succeeding section outlines the project's research strategy, and the data engineering, modelling, and evaluation steps.  By virtue  Thereafter, ...

\vspace{35pt}


# METHODS

The schematic illustration of *figure ...* outlines the project's data engineering, modelling, and evaluation steps, which underlie the project's research strategy.  This section briefly discusses the research strategy, and the steps.

```{r out.width = '90%', dpi = 85, fig.align = 'center', fig.cap = "The project's processing, analysis, modelling, and evaluation steps.  Please refer to the methodologies section for a brief description of (a) the patient flow weights, and (b) the estimation of NHS trust level measures via flow weights and LTLA level measures.  MSOA: middle layer super output area, LTLA: lower tier local authority, ONS: office for national statistics, NHS: national health service, PHE: Public Health England."}
knitr::include_graphics(path = 'images/flow.pdf', auto_pdf = getOption(x = "knitr.graphics.auto_pdf", default = TRUE),
                        dpi = NULL,  error = getOption(x = "knitr.graphics.error", default = TRUE)
)
```

## RESEARCH STRATEGY

In progress $\ldots$ includes research strategy [@Oates2006]

\vspace{20pt}

## DATA ENGINEERING

### Data Collection.

The data sources are: (a) the [coronavirus.data.gov.uk](https://coronavirus.data.gov.uk/details/developers-guide/main-api) application programming interface (API) for England's SARS-CoV-2 infections measures, (b) the [office for national statistics (ONS)](https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/middlesuperoutputareamidyearpopulationestimates) for population estimates, (c) [Public Health England (PHE)](https://app.box.com/s/qh8gzpzeo1firv1ezfxx2e6c4tgtrudl) for the annual intake of patients from one or more middle layer super output areas to an NHS Trust, and (d) the [Open Geography Portal (geoportal)](https://geoportal.statistics.gov.uk/search?collection=Dataset&sort=name&tags=all(LUP_MSOA_WD_LAD)) for the middle layer super output area (MSOA) $\leftrightarrow$ lower tier local authority (LTLA) geographic codes mappings.

\vspace{10pt}

### Structuring & Integrating.

The structuring and integrating segment of $fig. 4$ ensures that all the data sets

* have a [structured data file](https://www.ibm.com/cloud/blog/structured-vs-unstructured-data) set up, and
* are appropriately mapped

as illustrated.

\vspace{10pt}

### Features Engineering.

The aim of the feature engineering segment is the construction of the design matrix & outcome vector variables.  The design matrix variables are the set of predictors, i.e., independent variables.  ... *fig. 1* outlines the variables-construction steps, and the variables are

\vspace{10pt}

* ``covidOccupiedBeds``: The no. of beds occupied by coronavirus disease patients.

* ``covidOccupiedMVBeds``: The no. of mechanical ventilation beds occupied by coronavirus disease patients.

* ``estimatedNewAdmissions``: **The outcome variable**.   Estimated by NHS England.

* ``EDC0-4``, ``EDC5-9``, ..., ``EDC90+``: The estimated daily cases (EDC) by age group.

* ``newDeaths28DaysByDeathDate``: The no. of estimated daily deaths, such that each death occurred *within 28 days of a first positive laboratory-confirmed test*.

* ``EDV12-15``, ``EDV16-17``, ..., ``EDV90+``: The estimated no. of daily vaccinations (EDV) by age group; second vaccinations.

\vspace{10pt}

The first three are original NHS Trust level measures available via the [coronavirus.data.gov.uk](https://coronavirus.data.gov.uk) API, whereas the remaining variables are project estimated NHS Trust level measures.  The project estimates rely on (a) the LTLA Level measures of the API, and (b) ...

\vspace{20pt}

## MODELLING

### The Algorithms

\textcolor{blue}{The SARS-CoV-2 infections measures have both spatial and temporal features, i.e., the spatially spread set of NHS Trusts, and the infection dynamics, respectively.}  A number of algorithms have been developed for such prediction challenges ... Long short-term memory (LSTM) [@Hochreiter1997], Gated Recurrent Unit (GRU) [@Cho2014],  Convolutional Neural Networks (CNN) [@Bai2018].

\textcolor{blue}{
**LSTM**: In RNN, each layer takes the input data and the hidden state of past hidden state and outputs the hidden state, then this hidden state is given along with the input to the next layer. This hidden state holds the short-term memory. For the solution that requires long term memory, RNN would not be feasible option. To overcome this shortcoming we introduce LSTM. In LSTM, each layer outputs cell state which  is responsible for holding the long-time memory in addition to the hidden state. A LSTM cell contains simple RNN cells, cell states, forget gates, input gates and output gates. Input data and hidden state is given as input to all the components in the LSTM cell. Forget gate determines what to dismiss from the input and hidden state and hand that information to the cell state. Input gate in addition with the simple RNN cell determines what new information should be added to the cell state. This is outputted as cell state of the layer. Cell state value is also given as the input to the output gate to create a hidden state for the current layer. Hidden state and the cell state is given as the input to the next layer and the process continuous.}

\textcolor{blue}{
**GRU**: In contrast with LSTM, GRU has only hidden state. But it holds both the long term and short-term memory unlike the traditional RNN. GRU has two gates, the update gate and reset gate. The update gate determines how much to retain of the past memory. Reset gate determines how much past memory to forget. Reset gate output is used with the past hidden state and the input data to find the current memory content. This current memory content is used along with the update gate output and past hidden state to find the current hidden state output. This hidden state is then passed as the input to the next layer and the process continuous.}

\textcolor{blue}{
**CNN**: Though the CNN is famous for computer vision, the one-dimensional convolution is useful for timeseries ... CNN has filters that slides over the data to capture the features of the data. These filters are the learnt by training. The filters are followed by pooling to reduce the size of the parameters that are learnt by the algorithm.}

\vspace{10pt}

### Forecasting & History

The outlined algorithms ... addressed via modelling w.r.t. varying historical data windows.  Altogether ... forecasting 15 days into the future w.r.t. "varying days of history" ... via window logic

\vspace{10pt}

### Pre-modelling Procedures

* temporal splitting ... training, validation, and testing data sets
* reconstructing
* differencing
* normalisation

\vspace{20pt}

## EVALUATION

The results section summarises the modelling results.  Model evaluation is via the error measures

$$\text{loss} = \frac{1}{N} \sum^{N}_{n = 1} {(y_{t}(n) - y_{p}(n))^2} $$

$$\text{MAE} = \frac{1}{N} \sum^{N}_{n = 1} {|y_{t}(n) - y_{p}(n)|}$$

wherein

\vspace{10pt}

\begin{center}
    \begin{tabular}{c p{0.65\linewidth}l}\footnotesize
    variable & description \\
    $y_{t}$ & a true outcome value \\
    $y_{p}$ & a predicted outcome value \\
    $\text{loss}$  & the mean squared error \\
    $text{MAE}$ & the mean absolute error\\
    $N$ & the length of the outcome vector\\
    \end{tabular}
    \captionof{table}{The error formulae terms.}
\end{center}

\vspace{35pt}

# RESULTS

## MODEL EVALUATION

```{r out.width = '55%', fig.height = 8, fig.align = 'center', fig.cap = 'MAE w.r.t. the ...'}
endpoints <- EvaluationEndpointsData()
EndpointsMAE(endpoints = endpoints)
```




```{r out.width = '55%', fig.height = 8, fig.align = 'center', fig.cap = 'Loss w.r.t. the ...'}
EndpointsLoss(endpoints = endpoints)
```

\pagebreak

```{r out.width = '85%', fig.height = 6.5, fig.align = 'center', fig.cap = 'Pending'}
melted <- EvaluationHistoriesData()
ValidationHistoryMAE(melted = melted)
```


```{r out.width = '85%', fig.height = 6.5, fig.align = 'center', fig.cap = 'The loss errors'}
ValidationHistoryLoss(melted = melted)
```

Project guide:

* Explain your results and what your analysis revealed ()

* What implications would your analysis' results have? How do your findings relate to the original question?

\vspace{20pt}

## BIASES & VALIDITY

* Were there potential biases in your work?

* Validity (remember to discuss what would have been done differently to address identified limitations)



\vspace{35pt}



# CONCLUSIONS


Project Guide:

* Reflection on the approach taken. (Appropriate?)

* How would you have improved the approach in future? (Alternative methodologies, models, etc)


\vspace{35pt}

# REFERENCES

